{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bcf122-31be-4712-99ca-affa65020246",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.13 requires langchain-core<0.2.0,>=0.1.33, but you have langchain-core 0.3.45 which is incompatible.\n",
      "langchain-cohere 0.1.5 requires langchain-core<0.3,>=0.1.42, but you have langchain-core 0.3.45 which is incompatible.\n",
      "langchain-community 0.0.29 requires langchain-core<0.2.0,>=0.1.33, but you have langchain-core 0.3.45 which is incompatible.\n",
      "langchain-openai 0.1.7 requires langchain-core<0.3,>=0.1.46, but you have langchain-core 0.3.45 which is incompatible.\n",
      "langchain-text-splitters 0.0.2 requires langchain-core<0.3,>=0.1.28, but you have langchain-core 0.3.45 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading langgraph-0.3.11-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langgraph) (0.1.53)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.20-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.57-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (0.1.147)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (8.5.0)\n",
      "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: anyio in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.4,>=0.1->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.4,>=0.1->langgraph) (2.0.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.0)\n",
      "Downloading langgraph-0.3.11-py3-none-any.whl (132 kB)\n",
      "   ---------------------------------------- 0.0/132.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/132.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/132.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/132.5 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/132.5 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/132.5 kB 217.9 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 30.7/132.5 kB 217.9 kB/s eta 0:00:01\n",
      "   ------------------ -------------------- 61.4/132.5 kB 233.8 kB/s eta 0:00:01\n",
      "   ------------------ -------------------- 61.4/132.5 kB 233.8 kB/s eta 0:00:01\n",
      "   --------------------- ----------------- 71.7/132.5 kB 196.9 kB/s eta 0:00:01\n",
      "   --------------------- ----------------- 71.7/132.5 kB 196.9 kB/s eta 0:00:01\n",
      "   --------------------- ----------------- 71.7/132.5 kB 196.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 102.4/132.5 kB 210.9 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 102.4/132.5 kB 210.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 122.9/132.5 kB 212.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 132.5/132.5 kB 217.6 kB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-2.0.20-py3-none-any.whl (39 kB)\n",
      "Downloading langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
      "   ---------------------------------------- 0.0/415.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/415.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/415.9 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/415.9 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/415.9 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/415.9 kB 186.2 kB/s eta 0:00:03\n",
      "   -- ------------------------------------ 30.7/415.9 kB 186.2 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 41.0/415.9 kB 140.3 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 41.0/415.9 kB 140.3 kB/s eta 0:00:03\n",
      "   --- ----------------------------------- 41.0/415.9 kB 140.3 kB/s eta 0:00:03\n",
      "   ----- --------------------------------- 61.4/415.9 kB 163.6 kB/s eta 0:00:03\n",
      "   ----- --------------------------------- 61.4/415.9 kB 163.6 kB/s eta 0:00:03\n",
      "   ------ -------------------------------- 71.7/415.9 kB 151.0 kB/s eta 0:00:03\n",
      "   ------ -------------------------------- 71.7/415.9 kB 151.0 kB/s eta 0:00:03\n",
      "   ------ -------------------------------- 71.7/415.9 kB 151.0 kB/s eta 0:00:03\n",
      "   ------ -------------------------------- 71.7/415.9 kB 151.0 kB/s eta 0:00:03\n",
      "   ------ -------------------------------- 71.7/415.9 kB 151.0 kB/s eta 0:00:03\n",
      "   -------- ------------------------------ 92.2/415.9 kB 127.8 kB/s eta 0:00:03\n",
      "   -------- ------------------------------ 92.2/415.9 kB 127.8 kB/s eta 0:00:03\n",
      "   -------- ------------------------------ 92.2/415.9 kB 127.8 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 112.6/415.9 kB 128.5 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 112.6/415.9 kB 128.5 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 112.6/415.9 kB 128.5 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 112.6/415.9 kB 128.5 kB/s eta 0:00:03\n",
      "   ----------- -------------------------- 122.9/415.9 kB 116.2 kB/s eta 0:00:03\n",
      "   ----------- -------------------------- 122.9/415.9 kB 116.2 kB/s eta 0:00:03\n",
      "   ----------- -------------------------- 122.9/415.9 kB 116.2 kB/s eta 0:00:03\n",
      "   ------------- ------------------------ 143.4/415.9 kB 119.9 kB/s eta 0:00:03\n",
      "   ------------- ------------------------ 143.4/415.9 kB 119.9 kB/s eta 0:00:03\n",
      "   -------------- ----------------------- 153.6/415.9 kB 117.6 kB/s eta 0:00:03\n",
      "   -------------- ----------------------- 153.6/415.9 kB 117.6 kB/s eta 0:00:03\n",
      "   --------------- ---------------------- 174.1/415.9 kB 126.3 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 174.1/415.9 kB 126.3 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 194.6/415.9 kB 131.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 194.6/415.9 kB 131.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 194.6/415.9 kB 131.0 kB/s eta 0:00:02\n",
      "   ----------------- -------------------- 194.6/415.9 kB 131.0 kB/s eta 0:00:02\n",
      "   ------------------ ------------------- 204.8/415.9 kB 122.1 kB/s eta 0:00:02\n",
      "   ------------------ ------------------- 204.8/415.9 kB 122.1 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 225.3/415.9 kB 128.6 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 225.3/415.9 kB 128.6 kB/s eta 0:00:02\n",
      "   -------------------- ----------------- 225.3/415.9 kB 128.6 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 235.5/415.9 kB 123.2 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 235.5/415.9 kB 123.2 kB/s eta 0:00:02\n",
      "   --------------------- ---------------- 235.5/415.9 kB 123.2 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 256.0/415.9 kB 124.8 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 256.0/415.9 kB 124.8 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 256.0/415.9 kB 124.8 kB/s eta 0:00:02\n",
      "   ----------------------- -------------- 256.0/415.9 kB 124.8 kB/s eta 0:00:02\n",
      "   ------------------------- ------------ 276.5/415.9 kB 125.3 kB/s eta 0:00:02\n",
      "   ------------------------- ------------ 276.5/415.9 kB 125.3 kB/s eta 0:00:02\n",
      "   -------------------------- ----------- 286.7/415.9 kB 123.7 kB/s eta 0:00:02\n",
      "   -------------------------- ----------- 286.7/415.9 kB 123.7 kB/s eta 0:00:02\n",
      "   ---------------------------- --------- 307.2/415.9 kB 127.6 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 307.2/415.9 kB 127.6 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 317.4/415.9 kB 126.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 317.4/415.9 kB 126.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 317.4/415.9 kB 126.8 kB/s eta 0:00:01\n",
      "   ----------------------------- -------- 317.4/415.9 kB 126.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 337.9/415.9 kB 124.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 337.9/415.9 kB 124.8 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 337.9/415.9 kB 124.8 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 358.4/415.9 kB 126.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 358.4/415.9 kB 126.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 358.4/415.9 kB 126.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 358.4/415.9 kB 126.6 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 358.4/415.9 kB 126.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 368.6/415.9 kB 119.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 368.6/415.9 kB 119.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 368.6/415.9 kB 119.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 389.1/415.9 kB 122.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 389.1/415.9 kB 122.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 399.4/415.9 kB 121.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 415.9/415.9 kB 124.8 kB/s eta 0:00:00\n",
      "Downloading langgraph_prebuilt-0.1.3-py3-none-any.whl (24 kB)\n",
      "Downloading langgraph_sdk-0.1.57-py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/46.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/46.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/46.0 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 10.2/46.0 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 30.7/46.0 kB 131.3 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 30.7/46.0 kB 131.3 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 30.7/46.0 kB 131.3 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.0/46.0 kB 103.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.0/46.0 kB 120.4 kB/s eta 0:00:00\n",
      "Downloading msgpack-1.1.0-cp311-cp311-win_amd64.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/74.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/74.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/74.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.9 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 10.2/74.9 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 30.7/74.9 kB 100.9 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 30.7/74.9 kB 100.9 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 41.0/74.9 kB 98.1 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 41.0/74.9 kB 98.1 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 41.0/74.9 kB 98.1 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 61.4/74.9 kB 116.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 71.7/74.9 kB 122.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 74.9/74.9 kB 125.3 kB/s eta 0:00:00\n",
      "Installing collected packages: msgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.1.53\n",
      "    Uninstalling langchain-core-0.1.53:\n",
      "      Successfully uninstalled langchain-core-0.1.53\n",
      "Successfully installed langchain-core-0.3.45 langgraph-0.3.11 langgraph-checkpoint-2.0.20 langgraph-prebuilt-0.1.3 langgraph-sdk-0.1.57 msgpack-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da13075-ddf8-486a-bc85-b99bc21bda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable Proxy\n",
    "\n",
    "import os\n",
    "\n",
    "def clear_proxy_settings():\n",
    "    for var in [\"HTTP_PROXY\", \"HTTPS_PROXY\", \"ALL_PROXY\", \"http_proxy\", \"https_proxy\", \"all_proxy\"]:\n",
    "        if var in os.environ:\n",
    "            del os.environ[var]\n",
    "\n",
    "clear_proxy_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c413571f-c824-49be-ba5a-97e9a8476a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What's the current status of Project Beta?\n",
      "Response: Error: Unable to get response from Ollama (Status code: 500)\n",
      "\n",
      "Query: How should I handle a new client inquiry?\n",
      "Response: Error: Unable to get response from Ollama (Status code: 500)\n",
      "\n",
      "Query: What was Michael working on in our last standup?\n",
      "Response: Error: Unable to get response from Ollama (Status code: 500)\n"
     ]
    }
   ],
   "source": [
    "# memory.py - using Ollama for model inference\n",
    "\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional\n",
    "import json\n",
    "from datetime import datetime\n",
    "import requests  # For Ollama API calls\n",
    "\n",
    "class Result:\n",
    "    \"\"\"Wrapper class to mimic the result object from LangGraph's InMemoryStore\"\"\"\n",
    "    def __init__(self, id, value):\n",
    "        self.id = id\n",
    "        self.value = value\n",
    "\n",
    "class SimpleMemoryStore:\n",
    "    \"\"\"A simple in-memory store that doesn't require embeddings or external APIs\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Main storage dictionary\n",
    "        self.storage = {}\n",
    "    \n",
    "    def put(self, namespace, key, value):\n",
    "        \"\"\"Store data in the specified namespace under the given key\"\"\"\n",
    "        ns_str = self._format_namespace(namespace)\n",
    "        if ns_str not in self.storage:\n",
    "            self.storage[ns_str] = {}\n",
    "        self.storage[ns_str][key] = value\n",
    "        return True\n",
    "    \n",
    "    def get(self, namespace, key):\n",
    "        \"\"\"Retrieve data from the specified namespace under the given key\"\"\"\n",
    "        ns_str = self._format_namespace(namespace)\n",
    "        if ns_str not in self.storage or key not in self.storage[ns_str]:\n",
    "            return None\n",
    "        \n",
    "        return Result(key, self.storage[ns_str][key])\n",
    "    \n",
    "    def search(self, namespace, query, filter_func=None):\n",
    "        \"\"\"Simple keyword-based search (no embeddings)\"\"\"\n",
    "        ns_str = self._format_namespace(namespace)\n",
    "        if ns_str not in self.storage:\n",
    "            return []\n",
    "        \n",
    "        results = []\n",
    "        for key, value in self.storage[ns_str].items():\n",
    "            # Very basic text search - check if query exists in the key or stringified value\n",
    "            value_str = json.dumps(value).lower()\n",
    "            match_found = (query.lower() in key.lower() or \n",
    "                          query.lower() in value_str)\n",
    "            \n",
    "            if match_found:\n",
    "                # Apply filter if provided\n",
    "                result = Result(key, value)\n",
    "                if filter_func is None or filter_func(result):\n",
    "                    results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _format_namespace(self, namespace):\n",
    "        \"\"\"Convert tuple namespace to string representation\"\"\"\n",
    "        if isinstance(namespace, tuple):\n",
    "            return \"/\".join(namespace)\n",
    "        return str(namespace)\n",
    "\n",
    "\n",
    "# Initialize our simple store\n",
    "store = SimpleMemoryStore()\n",
    "\n",
    "\n",
    "class EpisodicMemory:\n",
    "    \"\"\"Stores specific experiences and events\"\"\"\n",
    "    def __init__(self, store, namespace):\n",
    "        self.store = store\n",
    "        self.namespace = namespace\n",
    "    \n",
    "    def add_interaction(self, interaction_id, content):\n",
    "        \"\"\"Store a specific interaction or event\"\"\"\n",
    "        self.store.put(\n",
    "            self.namespace,\n",
    "            f\"interaction:{interaction_id}\",\n",
    "            {\"content\": content, \"type\": \"episodic\", \"timestamp\": str(datetime.now())}\n",
    "        )\n",
    "        return f\"Stored interaction {interaction_id}\"\n",
    "    \n",
    "    def recall_interaction(self, interaction_id):\n",
    "        \"\"\"Retrieve a specific interaction by ID\"\"\"\n",
    "        result = self.store.get(self.namespace, f\"interaction:{interaction_id}\")\n",
    "        if result is None:\n",
    "            return f\"No memory found for interaction {interaction_id}\"\n",
    "        return result.value['content']\n",
    "    \n",
    "    def search_interactions(self, query):\n",
    "        \"\"\"Search for relevant interactions based on content\"\"\"\n",
    "        results = self.store.search(\n",
    "            self.namespace, \n",
    "            query,\n",
    "            filter_func=lambda x: x.value.get('type') == 'episodic'\n",
    "        )\n",
    "        return [r.value['content'] for r in results]\n",
    "\n",
    "\n",
    "class SemanticMemory:\n",
    "    \"\"\"Stores factual knowledge and concepts\"\"\"\n",
    "    def __init__(self, store, namespace):\n",
    "        self.store = store\n",
    "        self.namespace = namespace\n",
    "    \n",
    "    def add_knowledge(self, key, facts):\n",
    "        \"\"\"Store factual knowledge about a concept\"\"\"\n",
    "        self.store.put(\n",
    "            self.namespace,\n",
    "            f\"concept:{key}\",\n",
    "            {\"facts\": facts, \"type\": \"semantic\"}\n",
    "        )\n",
    "        return f\"Stored knowledge about {key}\"\n",
    "    \n",
    "    def get_knowledge(self, key):\n",
    "        \"\"\"Retrieve knowledge about a specific concept\"\"\"\n",
    "        result = self.store.get(self.namespace, f\"concept:{key}\")\n",
    "        if result is None:\n",
    "            return f\"No knowledge found about {key}\"\n",
    "        return result.value['facts']\n",
    "    \n",
    "    def search_knowledge(self, query):\n",
    "        \"\"\"Search for relevant knowledge\"\"\"\n",
    "        results = self.store.search(\n",
    "            self.namespace, \n",
    "            query,\n",
    "            filter_func=lambda x: x.value.get('type') == 'semantic'\n",
    "        )\n",
    "        return [(r.id.split(':')[-1], r.value['facts']) for r in results]\n",
    "\n",
    "\n",
    "class ProceduralMemory:\n",
    "    \"\"\"Stores information about how to perform tasks or follow procedures\"\"\"\n",
    "    def __init__(self, store, namespace):\n",
    "        self.store = store\n",
    "        self.namespace = namespace\n",
    "    \n",
    "    def add_procedure(self, name, instructions):\n",
    "        \"\"\"Store a procedure or instructions for a task\"\"\"\n",
    "        self.store.put(\n",
    "            self.namespace,\n",
    "            f\"procedure:{name}\",\n",
    "            {\"instructions\": instructions, \"type\": \"procedural\"}\n",
    "        )\n",
    "        return f\"Stored procedure {name}\"\n",
    "    \n",
    "    def get_procedure(self, name):\n",
    "        \"\"\"Retrieve instructions for a specific procedure\"\"\"\n",
    "        result = self.store.get(self.namespace, f\"procedure:{name}\")\n",
    "        if result is None:\n",
    "            return f\"No procedure found for {name}\"\n",
    "        return result.value['instructions']\n",
    "    \n",
    "    def update_procedure(self, name, new_instructions):\n",
    "        \"\"\"Update existing procedure instructions\"\"\"\n",
    "        existing = self.store.get(self.namespace, f\"procedure:{name}\")\n",
    "        if existing is None:\n",
    "            return f\"No procedure found for {name}\"\n",
    "        \n",
    "        self.store.put(\n",
    "            self.namespace,\n",
    "            f\"procedure:{name}\",\n",
    "            {\"instructions\": new_instructions, \"type\": \"procedural\"}\n",
    "        )\n",
    "        return f\"Updated procedure {name}\"\n",
    "    \n",
    "    def search_procedures(self, query):\n",
    "        \"\"\"Search for relevant procedures\"\"\"\n",
    "        results = self.store.search(\n",
    "            self.namespace, \n",
    "            query,\n",
    "            filter_func=lambda x: x.value.get('type') == 'procedural'\n",
    "        )\n",
    "        return [(r.id.split(':')[-1], r.value['instructions']) for r in results]\n",
    "\n",
    "\n",
    "class IntegratedMemory:\n",
    "    \"\"\"Combines episodic, semantic, and procedural memory into a single system\"\"\"\n",
    "    def __init__(self, user_id):\n",
    "        self.user_id = user_id\n",
    "        self.store = store  # Using the globally defined store\n",
    "        \n",
    "        # Initialize all memory types\n",
    "        self.episodic = EpisodicMemory(store, (user_id, \"episodes\"))\n",
    "        self.semantic = SemanticMemory(store, (user_id, \"knowledge\"))\n",
    "        self.procedural = ProceduralMemory(store, (user_id, \"procedures\"))\n",
    "    \n",
    "    def query_memory(self, query):\n",
    "        \"\"\"Query across all memory types\"\"\"\n",
    "        results = {\n",
    "            \"episodic\": self.episodic.search_interactions(query),\n",
    "            \"semantic\": self.semantic.search_knowledge(query),\n",
    "            \"procedural\": self.procedural.search_procedures(query)\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def remember_interaction(self, interaction_id, content):\n",
    "        return self.episodic.add_interaction(interaction_id, content)\n",
    "    \n",
    "    def learn_fact(self, concept, facts):\n",
    "        return self.semantic.add_knowledge(concept, facts)\n",
    "    \n",
    "    def learn_procedure(self, name, instructions):\n",
    "        return self.procedural.add_procedure(name, instructions)\n",
    "\n",
    "\n",
    "class OllamaMemoryAssistant:\n",
    "    \"\"\"Assistant using Ollama instead of HuggingFace models\"\"\"\n",
    "    def __init__(self, user_id, model_name=\"gemma3:12b\", base_url=\"http://localhost:11434\"):\n",
    "        self.memory = IntegratedMemory(user_id)\n",
    "        self.model_name = model_name\n",
    "        self.base_url = base_url\n",
    "    \n",
    "    def _format_memory_context(self, memory_results):\n",
    "        context = [\"MEMORY CONTEXT:\"]\n",
    "        \n",
    "        if memory_results[\"episodic\"]:\n",
    "            context.append(\"\\nPast experiences:\")\n",
    "            for memory in memory_results[\"episodic\"][:3]:  # Limit to top 3\n",
    "                context.append(f\"- {memory}\")\n",
    "        \n",
    "        if memory_results[\"semantic\"]:\n",
    "            context.append(\"\\nKnown facts:\")\n",
    "            for concept, facts in memory_results[\"semantic\"][:3]:  # Limit to top 3\n",
    "                context.append(f\"- {concept}: {facts}\")\n",
    "        \n",
    "        if memory_results[\"procedural\"]:\n",
    "            context.append(\"\\nRelevant procedures:\")\n",
    "            for name, instructions in memory_results[\"procedural\"][:3]:  # Limit to top 3\n",
    "                context.append(f\"- {name}: {instructions}\")\n",
    "        \n",
    "        return \"\\n\".join(context)\n",
    "\n",
    "    def process_query(self, query):\n",
    "        \"\"\"Process a query using Ollama API\"\"\"\n",
    "        # Search memory\n",
    "        memory_results = self.memory.query_memory(query)\n",
    "        memory_context = self._format_memory_context(memory_results)\n",
    "        \n",
    "        # Create prompt with memory context\n",
    "        prompt = f\"\"\"You are an assistant with access to the user's memories.\n",
    "Use the following memory context to answer the query:\n",
    "\n",
    "{memory_context}\n",
    "\n",
    "User query: {query}\"\"\"\n",
    "        \n",
    "        # Call Ollama API\n",
    "        response = requests.post(\n",
    "            f\"{self.base_url}/api/generate\",\n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            generated_text = result.get(\"response\", \"\")\n",
    "        else:\n",
    "            generated_text = f\"Error: Unable to get response from Ollama (Status code: {response.status_code})\"\n",
    "        \n",
    "        # Store this interaction in episodic memory\n",
    "        interaction_id = f\"query-{hash(query)}\"\n",
    "        self.memory.remember_interaction(interaction_id, {\n",
    "            \"query\": query,\n",
    "            \"response\": generated_text,\n",
    "            \"timestamp\": str(datetime.now())\n",
    "        })\n",
    "        \n",
    "        return generated_text\n",
    "    \n",
    "    def learn_fact(self, concept, facts):\n",
    "        return self.memory.learn_fact(concept, facts)\n",
    "    \n",
    "    def learn_procedure(self, name, instructions):\n",
    "        return self.memory.learn_procedure(name, instructions)\n",
    "    \n",
    "    def remember_interaction(self, interaction_id, content):\n",
    "        return self.memory.remember_interaction(interaction_id, content)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a memory-enhanced assistant using Ollama\n",
    "    assistant = OllamaMemoryAssistant(\"user789\", model_name=\"gemma3:12b\")\n",
    "    \n",
    "    # Pre-load some memories\n",
    "    assistant.learn_fact(\"project_beta\", {\n",
    "        \"description\": \"Mobile payment processing system\",\n",
    "        \"status\": \"In development\",\n",
    "        \"deadline\": \"Q2 2024\",\n",
    "        \"team\": [\"John\", \"Sarah\", \"Michael\"]\n",
    "    })\n",
    "    \n",
    "    assistant.learn_procedure(\"handle_client_inquiry\", {\n",
    "        \"steps\": [\n",
    "            \"1. Acknowledge receipt within 2 hours\",\n",
    "            \"2. Determine inquiry category (technical, billing, feature request)\",\n",
    "            \"3. Route to appropriate department or handle directly\",\n",
    "            \"4. Follow up within 24 hours with status update\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    assistant.remember_interaction(\"team-standup-2023-11-05\", {\n",
    "        \"event\": \"Daily standup\",\n",
    "        \"updates\": {\n",
    "            \"John\": \"Working on API integration\",\n",
    "            \"Sarah\": \"Finished UI redesign\",\n",
    "            \"Michael\": \"Debugging payment gateway issues\"\n",
    "        },\n",
    "        \"blockers\": [\"Waiting for credentials from payment provider\"]\n",
    "    })\n",
    "    \n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"What's the current status of Project Beta?\",\n",
    "        \"How should I handle a new client inquiry?\",\n",
    "        \"What was Michael working on in our last standup?\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        response = assistant.process_query(query)\n",
    "        print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52782a95-28bc-41fd-a4f3-c03a127f88fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
